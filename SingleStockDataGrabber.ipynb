{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets HighOpenLowClose Data of a single stock\n",
    "This Noteboock extracts HOLC Data from Yahoo finance and writes it into a csv file on drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOCK \n",
    "Name the Stock by entering the ticker symbol\n",
    "$\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock = [\"RNR\",]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run that Celle and that is it ...\n",
    "Watch out for the output at the bottom. Check if this is the stock and the data you actually want to see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN me ! I am main \n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 28 13:21:14 2021\n",
    "\n",
    "@author: Schroeder\n",
    "\"\"\"\n",
    "#https://www.dividendenadel.de/indexmonitor-maerz-2021/\n",
    "#zykliker: Chemie , rohstoofe (spaet im zyklus)Bautr√§ger, Maschiennebau, REITS, Banken, Versicheurngen, Autobauer, ReisenHotels, Kreuztfahreten\n",
    "#Antizyklishc/Defneisv: telekom, nestle, Metro,\n",
    "import os\n",
    "import sys\n",
    "\n",
    "###### Insert the following three lines to make any import lib in he project dir setup visible to an other\n",
    "###### Directory in the project setup\n",
    "\n",
    "currentdir = os.path.abspath('')\n",
    "parentdir = os.path.realpath(os.path.join(currentdir, '..'))\n",
    "sys.path.insert(0, parentdir) \n",
    "#############################################################\n",
    "\n",
    "from MomentumScreening import my_setup\n",
    "###\n",
    "### The whole /ETFS/ Tree has to be located on ame level as repository \n",
    "pfad = os.path.realpath(os.path.join(parentdir, 'ETFS'))\n",
    "logpfad = os.path.realpath(os.path.join(parentdir, 'LOG'))\n",
    "##########################################################################\n",
    "mypath = os.path.realpath(os.path.join(pfad, my_setup.specific_datapath)) \n",
    "\n",
    "output_path = mypath\n",
    "\n",
    "\n",
    "keyword = \"macro\"\n",
    "\n",
    "Universe = {'quellpfad':[pfad],\n",
    "            'quelldatei': [keyword], \n",
    "            'plotdir':[mypath],\n",
    "            'resdir':[mypath],\n",
    "            'vamsdir':[mypath],\n",
    "            'tmpdatadir':[mypath],\n",
    "            } \n",
    "\n",
    "\n",
    "Anzahl = 0 \n",
    "\n",
    "periode = \"15y\"\n",
    "ll=600\n",
    "\n",
    "\n",
    "print(Universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#https://www.tradingview.com/x/RHiQkrp0/\n",
    "\n",
    "\n",
    "quantil = 0.1\n",
    "riskquantil = 0.00005\n",
    "\n",
    "\n",
    "SingleEMAperiod = 50\n",
    "BenchmarkEMAperiod = 100\n",
    "#das Fenster um die Regression zu rechnen:\n",
    "roll_window = 60\n",
    "\n",
    "Num_of_positions = 10\n",
    "CutOff_positions = 20\n",
    "\n",
    "#desktoppfad = 'C:/Users/_schr/Desktop/'\n",
    "desktoppfad = output_path\n",
    "\n",
    "\n",
    "benchmarkfile = \"SPY.csv\"\n",
    "\n",
    "def figures_to_html(figs, filename=\"dashboard.html\"):\n",
    "    dashboard = open(filename, 'w')\n",
    "    dashboard.write(\"<html><head></head><body>\" + \"\\n\")\n",
    "    for fig in figs:\n",
    "        inner_html = fig.to_html().split('<body>')[1].split('</body>')[0]\n",
    "        dashboard.write(inner_html)\n",
    "    dashboard.write(\"</body></html>\" + \"\\n\")\n",
    "\n",
    "\n",
    "# Liest ETF historien von yahoo finance aus und macth ein ranking.\n",
    "\n",
    "\n",
    "\n",
    "from MomentumScreening import TickerSelector, regression, StockscreenerWinners_stats\n",
    "from lib import Indikatoren\n",
    "\n",
    " \n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import calendar\n",
    "\n",
    "\n",
    "# Imports\n",
    "from pandas_datareader import data as pdr\n",
    "#from yahoo_fin import stock_info as si\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "import os.path\n",
    "\n",
    "\n",
    "#lieferrt bei gegebenem datatfram mit datum als index das erste Datum, das letzte, und zwei \n",
    "# dazwischen \n",
    "\n",
    "\n",
    "def sort_final(liste):\n",
    "    liste[\"rang\"]= 0.1*liste[str(m)+\"d_rs\"]+0.9*liste[str(ll)+\"d_rs\"]\n",
    "    liste[\"ranking\"]=liste.rang.rank()\n",
    "\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "\n",
    "universe = pd.DataFrame(Universe)\n",
    "\n",
    "if my_setup.logger == \"On\":\n",
    "    fname = logpfad + \"\\\\\" + str(datetime.datetime.now().day)+ \"--\"+str(datetime.datetime.now().hour)+\"-\"+ str(datetime.datetime.now().minute)+\".log\"\n",
    "    logging.basicConfig(filename=fname,\n",
    "                        format=\"%(asctime)s %(message)s\", \n",
    "                        datefmt=\"%m/%d %I:%M:%S %p\", \n",
    "                    level=logging.INFO)  \n",
    "\n",
    "logging.info(\"Start DataGrabbing\")\n",
    "\n",
    "for index, row in universe.iterrows():\n",
    "    tickerfile = row[\"quellpfad\"]+row[\"quelldatei\"]+\".csv\"\n",
    "    plotfile = row[\"plotdir\"]\n",
    "    resfile =  row[\"resdir\"]\n",
    "    tmpdatafile = row[\"tmpdatadir\"]\n",
    "    vamsfile = row[\"vamsdir\"]\n",
    "\n",
    "    \n",
    "    logging.info(\"Grabbing: \"+row[\"quelldatei\"])\n",
    "\n",
    "    print(tmpdatafile)\n",
    "    print(plotfile)\n",
    "\n",
    "    #StockscreenerWinners_stats.cleardir(tmpdatafile)\n",
    "    #StockscreenerWinners_stats.cleardir(plotfile)\n",
    "\n",
    "    \n",
    "    true_tickers=[]\n",
    "    true_names = []\n",
    "    true_industry = []\n",
    "    true_sector = []\n",
    "    true_marketCap =[]\n",
    "    shit_list = []\n",
    "    \n",
    "    \n",
    "    ################### Anzahl Balken, also Handelstage !\n",
    "    xxs = 5\n",
    "    xs = 10\n",
    "    s = 21\n",
    "    m=50\n",
    "\n",
    "\n",
    "    ####################################################\n",
    "    ## HIer die Anzhal dr Kalendertage\n",
    "    xxs_d = xxs + 2\n",
    "    xs_d= xs + 4\n",
    "    s_d = s + 8\n",
    "    m_d = m + 20\n",
    "    l_d = ll + 24\n",
    "    \n",
    "    \n",
    "    \n",
    "    Anz = -1 \n",
    "    shitflag = False\n",
    "    while Anz <  Anzahl:\n",
    "        Anz=Anz+1\n",
    "        #print(\"################################\")\n",
    "        #print(\"Anzhal Wochen: \", Anz)\n",
    "        #print(\"################################\")\n",
    "        #end_date = enddatum \n",
    "         \n",
    "        #### End_date: Letztes Dtaum der Zeitreihe der Preise !\n",
    "        end_date = datetime.date.today()\n",
    "        end_date = end_date - datetime.timedelta(days=7*Anz)\n",
    "        bis = end_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        #### Start_date: Start der Zeitreihe der Preise in der Vergangeheit\n",
    "        dAll = l_d + 2 \n",
    "        start_date =  end_date - datetime.timedelta(days=dAll)\n",
    "        von = start_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        start_l = end_date - datetime.timedelta(days=l_d)\n",
    "        if start_l.weekday() == 5:\n",
    "            start_l=start_l -  datetime.timedelta(days=1)\n",
    "        if start_l.weekday() == 6:\n",
    "            start_l=start_l +  datetime.timedelta(days=1)\n",
    "        \n",
    "        start_m = end_date - datetime.timedelta(days=m_d)\n",
    "        if start_m.weekday() == 5:\n",
    "            start_m=start_m -  datetime.timedelta(days=1)\n",
    "        if start_m.weekday() == 6:\n",
    "            start_m=start_m +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_s = end_date - datetime.timedelta(days=s_d)\n",
    "        if start_s.weekday() == 5:\n",
    "            start_s=start_s -  datetime.timedelta(days=1)\n",
    "        if start_s.weekday() == 6:\n",
    "            start_s=start_s +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xs = end_date - datetime.timedelta(days=xs_d)\n",
    "        if start_xs.weekday() == 5:\n",
    "            start_xs=start_xs -  datetime.timedelta(days=1)\n",
    "        if start_xs.weekday() == 6:\n",
    "            start_xs=start_xs +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xxs = end_date - datetime.timedelta(days=xxs_d)\n",
    "        if start_xxs.weekday() == 5:\n",
    "            start_xxs=start_xxs -  datetime.timedelta(days=1)\n",
    "        if start_xxs.weekday() == 6:\n",
    "            start_xxs=start_xxs +  datetime.timedelta(days=1)\n",
    "        \n",
    "        all_dates = [start_l,start_m,start_s,start_xs,start_xxs]\n",
    "        \n",
    "        \n",
    "        # in form von strings:\n",
    "        \n",
    "        \n",
    "        \n",
    "        Zeitstempel= bis + \"__\" + von\n",
    "\n",
    "    \n",
    "        # S&P Index Returns\n",
    "        \n",
    "        counter =-1\n",
    "       \n",
    "        for ticker in stock:\n",
    "            df = pd.DataFrame()\n",
    "            print(ticker)\n",
    "\n",
    "            counter=counter+1\n",
    "            \n",
    "            # name des ETFs:\n",
    "            # Download abber_stats.historical data as CSV for each stock (makes the process faster)\n",
    "            sthwrong=True\n",
    "           \n",
    "            time.sleep(0.4)\n",
    "            oo = yf.Ticker(ticker)\n",
    "            print(oo)\n",
    "            time.sleep(0.4)  \n",
    "        #   df = yf.download(ticker, start=start_date.strftime(\"%Y-%m-%d\"), end=end_date.strftime(\"%Y-%m-%d\"))\n",
    "            try:\n",
    "                name = ticker\n",
    "                df = oo.history(periode)    \n",
    "            \n",
    "\n",
    "            except:\n",
    "                print(f\"{ticker}, {name}: korrupt. Keine History\")\n",
    "            try:\n",
    "                #print(\"name:\", name)\n",
    "                print(oo.info[\"longName\"])\n",
    "                name = oo.info[\"longName\"]\n",
    "            except:\n",
    "                print(f\"{ticker}: korrupt. Kein Longname\")\n",
    "            try:\n",
    "                    industry = oo.info[\"industry\"]\n",
    "                    sector = oo.info[\"sector\"]\n",
    "                    marketCap = int(oo.info[\"marketCap\"]/1000000000)\n",
    "                    print(industry,\"/\",sector,\"/\",marketCap, \"bln.$\")\n",
    "                    \n",
    "            except:\n",
    "                    industry=\"ETF\"    \n",
    "                    sector = \"sector\"\n",
    "                    marketCap=1\n",
    "             \n",
    "\n",
    "            if (len(df) < ll - 8) or ((end_date - df.index[-1].date()).days > 3 ):\n",
    "                l = len(df)\n",
    "                if l>0 :\n",
    "                    dt = str((end_date -  df.index[-1].date()).days)\n",
    "                else:\n",
    "                    dt = \"NaN\"\n",
    "                print(ticker, \" : On shit_list !\" )\n",
    "                print(\"date: \"+ str(end_date) + \" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name)+\"\\n\")\n",
    "                shit_list.append(ticker+\":\"+\" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name))\n",
    "            \n",
    "            if (len(df) >= ll - 8) and ((end_date -  df.index[-1].date()).days <= 3 ):\n",
    "                ## Checke, ob genug taeglioch Datensaetze geladne wurdne, um geforderte Historei zu analysieren\n",
    "                #long_date,middle_date, short_date,last_date = checkdate(df)\n",
    "                true_tickers.append(ticker)  \n",
    "                #tbiontrue names benennt die ticker, die tatsaechlich Daten lieferten.\n",
    "                true_names.append(name)  \n",
    "                true_industry.append(industry)  \n",
    "                true_sector.append(sector)\n",
    "                true_marketCap.append(marketCap)\n",
    "            \n",
    "                # Calculating returns relative to the market (returns multiple)\n",
    "                # fuer die letzen >>LaengeReturnHistorie<< Tage\n",
    "                df['Percent Change'] = df['Close'].pct_change()\n",
    "                df['Factor'] =  (df['Percent Change'] + 1).cumprod()\n",
    "                \n",
    "                stock_return = df['Factor'][-1]\n",
    "\n",
    "                df=Indikatoren.ATR(df,20)\n",
    "                df[\"EMA50\"]=df[\"Factor\"].ewm(span=50,adjust=False).mean()\n",
    "                df[\"EMA10\"]=df[\"Factor\"].ewm(span=10,adjust=False).mean()\n",
    "                df[\"EMA21\"]=df[\"Factor\"].ewm(span=21,adjust=False).mean()\n",
    "                df[\"EMA100\"]=df[\"Factor\"].ewm(span=100,adjust=False).mean()\n",
    "                df[\"EMA80\"]=df[\"Factor\"].ewm(span=80,adjust=False).mean()\n",
    "                df[\"EMA200\"]=df[\"Factor\"].ewm(span=200,adjust=False).mean()\n",
    "\n",
    "                df[\"momentum\"]=df[\"Factor\"]-df[\"EMA10\"]+df[\"EMA21\"] -df[\"EMA50\"] +df[\"EMA100\"]-df[\"EMA200\"]\n",
    "                \n",
    "                Indikatoren.MACD(df, 12, 26,9,\"_day\")\n",
    "                Indikatoren.MACD(df, 60, 130,45,\"_week\")    \n",
    "                \n",
    "\n",
    "                returns_multiple = 100*round(stock_return-1.0, 4)\n",
    "                print (f'Ticker: {ticker}; Returns Multiple: {returns_multiple:.2f} %\\n')\n",
    "                df.to_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', float_format='%.5f',)               \n",
    "            ## schreibe Ticker und die Longnames raus !\n",
    "            _ticker_names = pd.DataFrame(list(zip(true_tickers,true_names,true_industry,true_sector,true_marketCap)),\n",
    "                            columns=['ticker','name','industry',\"sector\",\"marketCap\"])\n",
    "            _ticker_names = _ticker_names.sort_values(\"ticker\")               \n",
    "            _ticker_names.to_csv(tmpdatafile +\"//\"+ \"_ticker_names.csv\",sep=\";\")  \n",
    "        \n",
    "        if shitflag==False:\n",
    "            shitflag = True    \n",
    "            shit_file = open(resfile+\"//\"+\"_shit\"+'.csv','w')\n",
    "            for item in shit_list:\n",
    "                shit_file.write(item+\"\\n\")\n",
    "            shit_file.close()    \n",
    "\n",
    "print(\"Done so far. This is what has been written to the csv..: \\n\\n\")\n",
    "df = pd.read_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', \n",
    "                            parse_dates=True,\n",
    "                            index_col=0)\n",
    "print(df.head(5))\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(df.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1eeed662d4e0aec0daec9fbef0f4bebea6e5a88731d55a40c66e53b57018d805"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 32-bit ('DataGrabber': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "072032cb4621292dbbe9c47ec612706b3a5fe1c2f3cd085779a3573cd04acabb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
