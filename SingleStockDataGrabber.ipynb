{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets HighOpenLowClose Data of a single stock\n",
    "This Noteboock extracts HOLC Data from Yahoo finance and writes it into a csv file on drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOCK \n",
    "Name the Stock by entering the ticker symbol\n",
    "$\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock = [\"XLU\",]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run that Celle and that is it ...\n",
    "Watch out for the output at the bottom. Check if this is the stock and the data you actually want to see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quellpfad': ['C:\\\\Temp\\\\Trading\\\\ETFS'], 'quelldatei': ['macro'], 'plotdir': ['C:\\\\Temp\\\\Trading\\\\ETFS\\\\Analyse_data'], 'resdir': ['C:\\\\Temp\\\\Trading\\\\ETFS\\\\Analyse_data'], 'vamsdir': ['C:\\\\Temp\\\\Trading\\\\ETFS\\\\Analyse_data'], 'tmpdatadir': ['C:\\\\Temp\\\\Trading\\\\ETFS\\\\Analyse_data']}\n"
     ]
    }
   ],
   "source": [
    "## RUN me ! I am main \n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 28 13:21:14 2021\n",
    "\n",
    "@author: Schroeder\n",
    "\"\"\"\n",
    "#https://www.dividendenadel.de/indexmonitor-maerz-2021/\n",
    "#zykliker: Chemie , rohstoofe (spaet im zyklus)Bauträger, Maschiennebau, REITS, Banken, Versicheurngen, Autobauer, ReisenHotels, Kreuztfahreten\n",
    "#Antizyklishc/Defneisv: telekom, nestle, Metro,\n",
    "import os\n",
    "import sys\n",
    "\n",
    "###### Insert the following three lines to make any import lib in he project dir setup visible to an other\n",
    "###### Directory in the project setup\n",
    "\n",
    "currentdir = os.path.abspath('')\n",
    "parentdir = os.path.realpath(os.path.join(currentdir, '..'))\n",
    "sys.path.insert(0, parentdir) \n",
    "#############################################################\n",
    "\n",
    "from MomentumScreening import my_setup\n",
    "###\n",
    "### The whole /ETFS/ Tree has to be located on ame level as repository \n",
    "pfad = os.path.realpath(os.path.join(parentdir, 'ETFS'))\n",
    "logpfad = os.path.realpath(os.path.join(parentdir, 'LOG'))\n",
    "##########################################################################\n",
    "mypath = os.path.realpath(os.path.join(pfad, my_setup.specific_datapath)) \n",
    "\n",
    "output_path = mypath\n",
    "\n",
    "\n",
    "keyword = \"macro\"\n",
    "\n",
    "Universe = {'quellpfad':[pfad],\n",
    "            'quelldatei': [keyword], \n",
    "            'plotdir':[mypath],\n",
    "            'resdir':[mypath],\n",
    "            'vamsdir':[mypath],\n",
    "            'tmpdatadir':[mypath],\n",
    "            } \n",
    "\n",
    "\n",
    "Anzahl = 0 \n",
    "\n",
    "periode = \"15y\"\n",
    "ll=600\n",
    "\n",
    "\n",
    "print(Universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\Trading\\ETFS\\Analyse_data\n",
      "C:\\Temp\\Trading\\ETFS\\Analyse_data\n",
      "XLU\n",
      "yfinance.Ticker object <XLU>\n",
      "Utilities Select Sector SPDR Fund\n",
      "Ticker: XLU; Returns Multiple: 172.27 %\n",
      "\n",
      "Done so far. This is what has been written to the csv..: \n",
      "\n",
      "\n",
      "                Open      High       Low     Close   Volume  Dividends  \\\n",
      "Date                                                                     \n",
      "2007-10-29  24.36494  24.53985  24.31830  24.43490  2730700        0.0   \n",
      "2007-10-30  24.55150  24.63313  24.30663  24.46405  3507100        0.0   \n",
      "2007-10-31  24.77890  24.87218  24.48738  24.74975  5754800        0.0   \n",
      "2007-11-01  24.43490  24.79055  24.24250  24.24250  6498400        0.0   \n",
      "2007-11-02  24.61564  24.61564  24.20752  24.44073  6411400        0.0   \n",
      "\n",
      "            Stock Splits  Percent Change   Factor  ATR20  ...   EMA100  \\\n",
      "Date                                                      ...            \n",
      "2007-10-29             0             NaN      NaN    NaN  ...      NaN   \n",
      "2007-10-30             0         0.00119  1.00119    NaN  ...  1.00119   \n",
      "2007-10-31             0         0.01168  1.01289    NaN  ...  1.00142   \n",
      "2007-11-01             0        -0.02050  0.99213    NaN  ...  1.00124   \n",
      "2007-11-02             0         0.00818  1.00024    NaN  ...  1.00122   \n",
      "\n",
      "              EMA80   EMA200  momentum  MACD_day  MACDsign_day  MACDdif_day  \\\n",
      "Date                                                                          \n",
      "2007-10-29      NaN      NaN       NaN   0.00000       0.00000      0.00000   \n",
      "2007-10-30  1.00119  1.00119   0.00000   0.00233       0.00129      0.00103   \n",
      "2007-10-31  1.00148  1.00131   0.01029   0.02691       0.01179      0.01512   \n",
      "2007-11-01  1.00125  1.00122  -0.00908   0.00540       0.00963     -0.00422   \n",
      "2007-11-02  1.00123  1.00121  -0.00084   0.00430       0.00804     -0.00374   \n",
      "\n",
      "            MACD_week  MACDsign_week  MACDdif_week  \n",
      "Date                                                \n",
      "2007-10-29    0.00000        0.00000       0.00000  \n",
      "2007-10-30    0.00051        0.00026       0.00025  \n",
      "2007-10-31    0.00600        0.00226       0.00374  \n",
      "2007-11-01    0.00234        0.00228       0.00006  \n",
      "2007-11-02    0.00233        0.00229       0.00004  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "-------------------------------------------------------------------\n",
      "             Open    High    Low  Close    Volume  Dividends  Stock Splits  \\\n",
      "Date                                                                         \n",
      "2022-10-24  63.65  64.340  63.15  63.84  10030500        0.0             0   \n",
      "2022-10-25  64.05  65.290  63.90  65.12  14201800        0.0             0   \n",
      "2022-10-26  65.47  65.800  64.81  65.09  13534400        0.0             0   \n",
      "2022-10-27  65.56  66.350  65.42  65.61  12256900        0.0             0   \n",
      "2022-10-28  65.88  66.725  65.79  66.53   2339917        0.0             0   \n",
      "\n",
      "            Percent Change   Factor    ATR20  ...   EMA100    EMA80   EMA200  \\\n",
      "Date                                          ...                              \n",
      "2022-10-24         0.00837  2.61266  1.76396  ...  2.86386  2.85337  2.84783   \n",
      "2022-10-25         0.02005  2.66504  1.73406  ...  2.85993  2.84872  2.84601   \n",
      "2022-10-26        -0.00046  2.66381  1.66319  ...  2.85604  2.84416  2.84420   \n",
      "2022-10-27         0.00799  2.68509  1.62479  ...  2.85266  2.84023  2.84262   \n",
      "2022-10-28         0.01402  2.72274  1.57624  ...  2.85009  2.83733  2.84142   \n",
      "\n",
      "            momentum  MACD_day  MACDsign_day  MACDdif_day  MACD_week  \\\n",
      "Date                                                                   \n",
      "2022-10-24  -0.10782  -2.28893      -2.50494      0.21601   -0.90298   \n",
      "2022-10-25  -0.06356  -2.03367      -2.41068      0.37702   -0.95975   \n",
      "2022-10-26  -0.07095  -1.81289      -2.29113      0.47823   -1.01388   \n",
      "2022-10-27  -0.05695  -1.57778      -2.14846      0.57068   -1.05581   \n",
      "2022-10-28  -0.02938  -1.30221      -1.97921      0.67700   -1.07909   \n",
      "\n",
      "            MACDsign_week  MACDdif_week  \n",
      "Date                                     \n",
      "2022-10-24        0.60966      -1.51263  \n",
      "2022-10-25        0.54142      -1.50117  \n",
      "2022-10-26        0.47380      -1.48767  \n",
      "2022-10-27        0.40729      -1.46310  \n",
      "2022-10-28        0.34267      -1.42176  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#https://www.tradingview.com/x/RHiQkrp0/\n",
    "\n",
    "\n",
    "quantil = 0.1\n",
    "riskquantil = 0.00005\n",
    "\n",
    "\n",
    "SingleEMAperiod = 50\n",
    "BenchmarkEMAperiod = 100\n",
    "#das Fenster um die Regression zu rechnen:\n",
    "roll_window = 60\n",
    "\n",
    "Num_of_positions = 10\n",
    "CutOff_positions = 20\n",
    "\n",
    "#desktoppfad = 'C:/Users/_schr/Desktop/'\n",
    "desktoppfad = output_path\n",
    "\n",
    "\n",
    "benchmarkfile = \"SPY.csv\"\n",
    "\n",
    "def figures_to_html(figs, filename=\"dashboard.html\"):\n",
    "    dashboard = open(filename, 'w')\n",
    "    dashboard.write(\"<html><head></head><body>\" + \"\\n\")\n",
    "    for fig in figs:\n",
    "        inner_html = fig.to_html().split('<body>')[1].split('</body>')[0]\n",
    "        dashboard.write(inner_html)\n",
    "    dashboard.write(\"</body></html>\" + \"\\n\")\n",
    "\n",
    "\n",
    "# Liest ETF historien von yahoo finance aus und macth ein ranking.\n",
    "\n",
    "\n",
    "\n",
    "from MomentumScreening import TickerSelector, regression, StockscreenerWinners_stats\n",
    "from lib import Indikatoren\n",
    "\n",
    " \n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import calendar\n",
    "\n",
    "\n",
    "# Imports\n",
    "from pandas_datareader import data as pdr\n",
    "#from yahoo_fin import stock_info as si\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "import os.path\n",
    "\n",
    "\n",
    "#lieferrt bei gegebenem datatfram mit datum als index das erste Datum, das letzte, und zwei \n",
    "# dazwischen \n",
    "\n",
    "\n",
    "def sort_final(liste):\n",
    "    liste[\"rang\"]= 0.1*liste[str(m)+\"d_rs\"]+0.9*liste[str(ll)+\"d_rs\"]\n",
    "    liste[\"ranking\"]=liste.rang.rank()\n",
    "\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "\n",
    "universe = pd.DataFrame(Universe)\n",
    "\n",
    "if my_setup.logger == \"On\":\n",
    "    fname = logpfad + \"\\\\\" + str(datetime.datetime.now().day)+ \"--\"+str(datetime.datetime.now().hour)+\"-\"+ str(datetime.datetime.now().minute)+\".log\"\n",
    "    logging.basicConfig(filename=fname,\n",
    "                        format=\"%(asctime)s %(message)s\", \n",
    "                        datefmt=\"%m/%d %I:%M:%S %p\", \n",
    "                    level=logging.INFO)  \n",
    "\n",
    "logging.info(\"Start DataGrabbing\")\n",
    "\n",
    "for index, row in universe.iterrows():\n",
    "    tickerfile = row[\"quellpfad\"]+row[\"quelldatei\"]+\".csv\"\n",
    "    plotfile = row[\"plotdir\"]\n",
    "    resfile =  row[\"resdir\"]\n",
    "    tmpdatafile = row[\"tmpdatadir\"]\n",
    "    vamsfile = row[\"vamsdir\"]\n",
    "\n",
    "    \n",
    "    logging.info(\"Grabbing: \"+row[\"quelldatei\"])\n",
    "\n",
    "    print(tmpdatafile)\n",
    "    print(plotfile)\n",
    "\n",
    "    #StockscreenerWinners_stats.cleardir(tmpdatafile)\n",
    "    #StockscreenerWinners_stats.cleardir(plotfile)\n",
    "\n",
    "    \n",
    "    true_tickers=[]\n",
    "    true_names = []\n",
    "    true_industry = []\n",
    "    true_sector = []\n",
    "    true_marketCap =[]\n",
    "    shit_list = []\n",
    "    \n",
    "    \n",
    "    ################### Anzahl Balken, also Handelstage !\n",
    "    xxs = 5\n",
    "    xs = 10\n",
    "    s = 21\n",
    "    m=50\n",
    "\n",
    "\n",
    "    ####################################################\n",
    "    ## HIer die Anzhal dr Kalendertage\n",
    "    xxs_d = xxs + 2\n",
    "    xs_d= xs + 4\n",
    "    s_d = s + 8\n",
    "    m_d = m + 20\n",
    "    l_d = ll + 24\n",
    "    \n",
    "    \n",
    "    \n",
    "    Anz = -1 \n",
    "    shitflag = False\n",
    "    while Anz <  Anzahl:\n",
    "        Anz=Anz+1\n",
    "        #print(\"################################\")\n",
    "        #print(\"Anzhal Wochen: \", Anz)\n",
    "        #print(\"################################\")\n",
    "        #end_date = enddatum \n",
    "         \n",
    "        #### End_date: Letztes Dtaum der Zeitreihe der Preise !\n",
    "        end_date = datetime.date.today()\n",
    "        end_date = end_date - datetime.timedelta(days=7*Anz)\n",
    "        bis = end_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        #### Start_date: Start der Zeitreihe der Preise in der Vergangeheit\n",
    "        dAll = l_d + 2 \n",
    "        start_date =  end_date - datetime.timedelta(days=dAll)\n",
    "        von = start_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        start_l = end_date - datetime.timedelta(days=l_d)\n",
    "        if start_l.weekday() == 5:\n",
    "            start_l=start_l -  datetime.timedelta(days=1)\n",
    "        if start_l.weekday() == 6:\n",
    "            start_l=start_l +  datetime.timedelta(days=1)\n",
    "        \n",
    "        start_m = end_date - datetime.timedelta(days=m_d)\n",
    "        if start_m.weekday() == 5:\n",
    "            start_m=start_m -  datetime.timedelta(days=1)\n",
    "        if start_m.weekday() == 6:\n",
    "            start_m=start_m +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_s = end_date - datetime.timedelta(days=s_d)\n",
    "        if start_s.weekday() == 5:\n",
    "            start_s=start_s -  datetime.timedelta(days=1)\n",
    "        if start_s.weekday() == 6:\n",
    "            start_s=start_s +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xs = end_date - datetime.timedelta(days=xs_d)\n",
    "        if start_xs.weekday() == 5:\n",
    "            start_xs=start_xs -  datetime.timedelta(days=1)\n",
    "        if start_xs.weekday() == 6:\n",
    "            start_xs=start_xs +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xxs = end_date - datetime.timedelta(days=xxs_d)\n",
    "        if start_xxs.weekday() == 5:\n",
    "            start_xxs=start_xxs -  datetime.timedelta(days=1)\n",
    "        if start_xxs.weekday() == 6:\n",
    "            start_xxs=start_xxs +  datetime.timedelta(days=1)\n",
    "        \n",
    "        all_dates = [start_l,start_m,start_s,start_xs,start_xxs]\n",
    "        \n",
    "        \n",
    "        # in form von strings:\n",
    "        \n",
    "        \n",
    "        \n",
    "        Zeitstempel= bis + \"__\" + von\n",
    "\n",
    "    \n",
    "        # S&P Index Returns\n",
    "        \n",
    "        counter =-1\n",
    "       \n",
    "        for ticker in stock:\n",
    "            df = pd.DataFrame()\n",
    "            print(ticker)\n",
    "\n",
    "            counter=counter+1\n",
    "            \n",
    "            # name des ETFs:\n",
    "            # Download abber_stats.historical data as CSV for each stock (makes the process faster)\n",
    "            sthwrong=True\n",
    "           \n",
    "            time.sleep(0.4)\n",
    "            oo = yf.Ticker(ticker)\n",
    "            print(oo)\n",
    "            time.sleep(0.4)  \n",
    "        #   df = yf.download(ticker, start=start_date.strftime(\"%Y-%m-%d\"), end=end_date.strftime(\"%Y-%m-%d\"))\n",
    "            try:\n",
    "                name = ticker\n",
    "                df = oo.history(periode)    \n",
    "            \n",
    "\n",
    "            except:\n",
    "                print(f\"{ticker}, {name}: korrupt. Keine History\")\n",
    "            try:\n",
    "                #print(\"name:\", name)\n",
    "                print(oo.info[\"longName\"])\n",
    "                name = oo.info[\"longName\"]\n",
    "            except:\n",
    "                print(f\"{ticker}: korrupt. Kein Longname\")\n",
    "            try:\n",
    "                    industry = oo.info[\"industry\"]\n",
    "                    sector = oo.info[\"sector\"]\n",
    "                    marketCap = int(oo.info[\"marketCap\"]/1000000000)\n",
    "                    print(industry,\"/\",sector,\"/\",marketCap, \"bln.$\")\n",
    "                    \n",
    "            except:\n",
    "                    industry=\"ETF\"    \n",
    "                    sector = \"sector\"\n",
    "                    marketCap=1\n",
    "             \n",
    "\n",
    "            if (len(df) < ll - 8) or ((end_date - df.index[-1].date()).days > 3 ):\n",
    "                l = len(df)\n",
    "                if l>0 :\n",
    "                    dt = str((end_date -  df.index[-1].date()).days)\n",
    "                else:\n",
    "                    dt = \"NaN\"\n",
    "                print(ticker, \" : On shit_list !\" )\n",
    "                print(\"date: \"+ str(end_date) + \" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name)+\"\\n\")\n",
    "                shit_list.append(ticker+\":\"+\" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name))\n",
    "            \n",
    "            if (len(df) >= ll - 8) and ((end_date -  df.index[-1].date()).days <= 3 ):\n",
    "                ## Checke, ob genug taeglioch Datensaetze geladne wurdne, um geforderte Historei zu analysieren\n",
    "                #long_date,middle_date, short_date,last_date = checkdate(df)\n",
    "                true_tickers.append(ticker)  \n",
    "                #tbiontrue names benennt die ticker, die tatsaechlich Daten lieferten.\n",
    "                true_names.append(name)  \n",
    "                true_industry.append(industry)  \n",
    "                true_sector.append(sector)\n",
    "                true_marketCap.append(marketCap)\n",
    "            \n",
    "                # Calculating returns relative to the market (returns multiple)\n",
    "                # fuer die letzen >>LaengeReturnHistorie<< Tage\n",
    "                df['Percent Change'] = df['Close'].pct_change()\n",
    "                df['Factor'] =  (df['Percent Change'] + 1).cumprod()\n",
    "                \n",
    "                stock_return = df['Factor'][-1]\n",
    "\n",
    "                df=Indikatoren.ATR(df,20)\n",
    "                df[\"EMA50\"]=df[\"Factor\"].ewm(span=50,adjust=False).mean()\n",
    "                df[\"EMA10\"]=df[\"Factor\"].ewm(span=10,adjust=False).mean()\n",
    "                df[\"EMA21\"]=df[\"Factor\"].ewm(span=21,adjust=False).mean()\n",
    "                df[\"EMA100\"]=df[\"Factor\"].ewm(span=100,adjust=False).mean()\n",
    "                df[\"EMA80\"]=df[\"Factor\"].ewm(span=80,adjust=False).mean()\n",
    "                df[\"EMA200\"]=df[\"Factor\"].ewm(span=200,adjust=False).mean()\n",
    "\n",
    "                df[\"momentum\"]=df[\"Factor\"]-df[\"EMA10\"]+df[\"EMA21\"] -df[\"EMA50\"] +df[\"EMA100\"]-df[\"EMA200\"]\n",
    "                \n",
    "                Indikatoren.MACD(df, 12, 26,9,\"_day\")\n",
    "                Indikatoren.MACD(df, 60, 130,45,\"_week\")    \n",
    "                \n",
    "\n",
    "                returns_multiple = 100*round(stock_return-1.0, 4)\n",
    "                print (f'Ticker: {ticker}; Returns Multiple: {returns_multiple:.2f} %\\n')\n",
    "                df.to_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', float_format='%.5f',)               \n",
    "            ## schreibe Ticker und die Longnames raus !\n",
    "            _ticker_names = pd.DataFrame(list(zip(true_tickers,true_names,true_industry,true_sector,true_marketCap)),\n",
    "                            columns=['ticker','name','industry',\"sector\",\"marketCap\"])\n",
    "            _ticker_names = _ticker_names.sort_values(\"ticker\")               \n",
    "            _ticker_names.to_csv(tmpdatafile +\"//\"+ \"_ticker_names.csv\",sep=\";\")  \n",
    "        \n",
    "        if shitflag==False:\n",
    "            shitflag = True    \n",
    "            shit_file = open(resfile+\"//\"+\"_shit\"+'.csv','w')\n",
    "            for item in shit_list:\n",
    "                shit_file.write(item+\"\\n\")\n",
    "            shit_file.close()    \n",
    "\n",
    "print(\"Done so far. This is what has been written to the csv..: \\n\\n\")\n",
    "df = pd.read_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', \n",
    "                            parse_dates=True,\n",
    "                            index_col=0)\n",
    "print(df.head(5))\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(df.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "072032cb4621292dbbe9c47ec612706b3a5fe1c2f3cd085779a3573cd04acabb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
