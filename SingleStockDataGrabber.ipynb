{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets HighOpenLowClose Data of a single stock\n",
    "This Noteboock extracts HOLC Data from Yahoo finance and writes it into a csv file on drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOCK \n",
    "Name the Stock by entering the ticker symbol\n",
    "$\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock = [\"USO\",]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run that Celle and that is it ...\n",
    "Watch out for the output at the bottom. Check if this is the stock and the data you actually want to see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quellpfad': ['C:\\\\Michael\\\\TRADING\\\\ETFS'], 'quelldatei': ['macro'], 'plotdir': ['C:\\\\Michael\\\\TRADING\\\\ETFS\\\\Analyse_data'], 'resdir': ['C:\\\\Michael\\\\TRADING\\\\ETFS\\\\Analyse_data'], 'vamsdir': ['C:\\\\Michael\\\\TRADING\\\\ETFS\\\\Analyse_data'], 'tmpdatadir': ['C:\\\\Michael\\\\TRADING\\\\ETFS\\\\Analyse_data']}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 28 13:21:14 2021\n",
    "\n",
    "@author: Schroeder\n",
    "\"\"\"\n",
    "#https://www.dividendenadel.de/indexmonitor-maerz-2021/\n",
    "#zykliker: Chemie , rohstoofe (spaet im zyklus)Bautr√§ger, Maschiennebau, REITS, Banken, Versicheurngen, Autobauer, ReisenHotels, Kreuztfahreten\n",
    "#Antizyklishc/Defneisv: telekom, nestle, Metro,\n",
    "import os\n",
    "import sys\n",
    "\n",
    "###### Insert the following three lines to make any import lib in he project dir setup visible to an other\n",
    "###### Directory in the project setup\n",
    "\n",
    "currentdir = os.path.abspath('')\n",
    "parentdir = os.path.realpath(os.path.join(currentdir, '..'))\n",
    "sys.path.insert(0, parentdir) \n",
    "#############################################################\n",
    "\n",
    "from MomentumScreening import my_setup\n",
    "###\n",
    "### The whole /ETFS/ Tree has to be located on ame level as repository \n",
    "pfad = os.path.realpath(os.path.join(parentdir, 'ETFS'))\n",
    "logpfad = os.path.realpath(os.path.join(parentdir, 'LOG'))\n",
    "##########################################################################\n",
    "mypath = os.path.realpath(os.path.join(pfad, my_setup.specific_datapath)) \n",
    "\n",
    "output_path = mypath\n",
    "\n",
    "\n",
    "keyword = \"macro\"\n",
    "\n",
    "Universe = {'quellpfad':[pfad],\n",
    "            'quelldatei': [keyword], \n",
    "            'plotdir':[mypath],\n",
    "            'resdir':[mypath],\n",
    "            'vamsdir':[mypath],\n",
    "            'tmpdatadir':[mypath],\n",
    "            } \n",
    "\n",
    "\n",
    "Anzahl = 0 \n",
    "\n",
    "periode = \"15y\"\n",
    "ll=600\n",
    "\n",
    "\n",
    "print(Universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Michael\\TRADING\\ETFS\\Analyse_data\n",
      "C:\\Michael\\TRADING\\ETFS\\Analyse_data\n",
      "USO\n",
      "yfinance.Ticker object <USO>\n",
      "United States Oil Fund, LP\n",
      "Ticker: USO; Returns Multiple: -83.43 %\n",
      "\n",
      "Done so far. This is what has been written to the csv..: \n",
      "\n",
      "\n",
      "                 Open       High        Low      Close  Volume  Dividends  \\\n",
      "Date                                                                        \n",
      "2007-08-31  448.23999  449.28000  444.32001  446.23999  128575          0   \n",
      "2007-09-04  447.67999  454.39999  447.44000  454.00000  127788          0   \n",
      "2007-09-05  452.07999  458.48001  451.67999  458.07999  141538          0   \n",
      "2007-09-06  463.60001  467.51999  454.95999  461.04001  523125          0   \n",
      "2007-09-07  460.39999  464.00000  456.79999  462.07999  534738          0   \n",
      "\n",
      "            Stock Splits  Percent Change   Factor  ATR20  ...   EMA100  \\\n",
      "Date                                                      ...            \n",
      "2007-08-31           0.0             NaN      NaN    NaN  ...      NaN   \n",
      "2007-09-04           0.0         0.01739  1.01739    NaN  ...  1.01739   \n",
      "2007-09-05           0.0         0.00899  1.02653    NaN  ...  1.01757   \n",
      "2007-09-06           0.0         0.00646  1.03317    NaN  ...  1.01788   \n",
      "2007-09-07           0.0         0.00226  1.03550    NaN  ...  1.01823   \n",
      "\n",
      "              EMA80   EMA200  momentum  MACD_day  MACDsign_day  MACDdif_day  \\\n",
      "Date                                                                          \n",
      "2007-08-31      NaN      NaN       NaN   0.00000       0.00000      0.00000   \n",
      "2007-09-04  1.01739  1.01739   0.00000   0.61903       0.34391      0.27513   \n",
      "2007-09-05  1.01762  1.01748   0.00804   1.42244       0.78593      0.63651   \n",
      "2007-09-06  1.01800  1.01764   0.01302   2.27181       1.28928      0.98254   \n",
      "2007-09-07  1.01843  1.01781   0.01377   2.99435       1.79650      1.19785   \n",
      "\n",
      "            MACD_week  MACDsign_week  MACDdif_week  \n",
      "Date                                                \n",
      "2007-08-31    0.00000        0.00000       0.00000  \n",
      "2007-09-04    0.13595        0.06949       0.06647  \n",
      "2007-09-05    0.33685        0.16260       0.17425  \n",
      "2007-09-06    0.57989        0.27398       0.30591  \n",
      "2007-09-07    0.82930        0.39513       0.43417  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "-------------------------------------------------------------------\n",
      "             Open   High      Low  Close   Volume  Dividends  Stock Splits  \\\n",
      "Date                                                                         \n",
      "2022-08-25  78.34  78.38  75.8300  76.50  2960200          0           0.0   \n",
      "2022-08-26  75.46  76.19  74.7700  75.85  2422000          0           0.0   \n",
      "2022-08-29  77.02  78.96  76.7100  78.69  3693500          0           0.0   \n",
      "2022-08-30  76.60  76.75  74.2800  75.47  4961300          0           0.0   \n",
      "2022-08-31  73.84  75.09  73.5507  73.95  2965043          0           0.0   \n",
      "\n",
      "            Percent Change   Factor    ATR20  ...   EMA100    EMA80   EMA200  \\\n",
      "Date                                          ...                              \n",
      "2022-08-25        -0.01973  0.17143  2.63100  ...  0.17045  0.17170  0.15923   \n",
      "2022-08-26        -0.00850  0.16998  2.54519  ...  0.17044  0.17166  0.15933   \n",
      "2022-08-29         0.03744  0.17634  2.59898  ...  0.17056  0.17177  0.15950   \n",
      "2022-08-30        -0.04092  0.16912  2.77146  ...  0.17053  0.17171  0.15960   \n",
      "2022-08-31        -0.02014  0.16572  2.69030  ...  0.17043  0.17156  0.15966   \n",
      "\n",
      "            momentum  MACD_day  MACDsign_day  MACDdif_day  MACD_week  \\\n",
      "Date                                                                   \n",
      "2022-08-25   0.01085  -0.19573      -0.82928      0.63354    1.96626   \n",
      "2022-08-26   0.00926  -0.12728      -0.68888      0.56160    1.92122   \n",
      "2022-08-29   0.01475   0.15436      -0.52023      0.67459    1.92711   \n",
      "2022-08-30   0.00771   0.11639      -0.39291      0.50929    1.87534   \n",
      "2022-08-31   0.00485  -0.03594      -0.32151      0.28557    1.79847   \n",
      "\n",
      "            MACDsign_week  MACDdif_week  \n",
      "Date                                     \n",
      "2022-08-25        3.89875      -1.93249  \n",
      "2022-08-26        3.81277      -1.89155  \n",
      "2022-08-29        3.73078      -1.80367  \n",
      "2022-08-30        3.65011      -1.77477  \n",
      "2022-08-31        3.56961      -1.77114  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#https://www.tradingview.com/x/RHiQkrp0/\n",
    "\n",
    "\n",
    "quantil = 0.1\n",
    "riskquantil = 0.00005\n",
    "\n",
    "\n",
    "SingleEMAperiod = 50\n",
    "BenchmarkEMAperiod = 100\n",
    "#das Fenster um die Regression zu rechnen:\n",
    "roll_window = 60\n",
    "\n",
    "Num_of_positions = 10\n",
    "CutOff_positions = 20\n",
    "\n",
    "#desktoppfad = 'C:/Users/_schr/Desktop/'\n",
    "desktoppfad = output_path\n",
    "\n",
    "\n",
    "benchmarkfile = \"SPY.csv\"\n",
    "\n",
    "def figures_to_html(figs, filename=\"dashboard.html\"):\n",
    "    dashboard = open(filename, 'w')\n",
    "    dashboard.write(\"<html><head></head><body>\" + \"\\n\")\n",
    "    for fig in figs:\n",
    "        inner_html = fig.to_html().split('<body>')[1].split('</body>')[0]\n",
    "        dashboard.write(inner_html)\n",
    "    dashboard.write(\"</body></html>\" + \"\\n\")\n",
    "\n",
    "\n",
    "# Liest ETF historien von yahoo finance aus und macth ein ranking.\n",
    "\n",
    "\n",
    "\n",
    "from MomentumScreening import TickerSelector, regression, StockscreenerWinners_stats\n",
    "from lib import Indikatoren\n",
    "\n",
    " \n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import calendar\n",
    "\n",
    "\n",
    "# Imports\n",
    "from pandas_datareader import data as pdr\n",
    "#from yahoo_fin import stock_info as si\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "import os.path\n",
    "\n",
    "\n",
    "#lieferrt bei gegebenem datatfram mit datum als index das erste Datum, das letzte, und zwei \n",
    "# dazwischen \n",
    "\n",
    "\n",
    "def sort_final(liste):\n",
    "    liste[\"rang\"]= 0.1*liste[str(m)+\"d_rs\"]+0.9*liste[str(ll)+\"d_rs\"]\n",
    "    liste[\"ranking\"]=liste.rang.rank()\n",
    "\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "\n",
    "universe = pd.DataFrame(Universe)\n",
    "\n",
    "if my_setup.logger == \"On\":\n",
    "    fname = logpfad + \"\\\\\" + str(datetime.datetime.now().day)+ \"--\"+str(datetime.datetime.now().hour)+\"-\"+ str(datetime.datetime.now().minute)+\".log\"\n",
    "    logging.basicConfig(filename=fname,\n",
    "                        format=\"%(asctime)s %(message)s\", \n",
    "                        datefmt=\"%m/%d %I:%M:%S %p\", \n",
    "                    level=logging.INFO)  \n",
    "\n",
    "logging.info(\"Start DataGrabbing\")\n",
    "\n",
    "for index, row in universe.iterrows():\n",
    "    tickerfile = row[\"quellpfad\"]+row[\"quelldatei\"]+\".csv\"\n",
    "    plotfile = row[\"plotdir\"]\n",
    "    resfile =  row[\"resdir\"]\n",
    "    tmpdatafile = row[\"tmpdatadir\"]\n",
    "    vamsfile = row[\"vamsdir\"]\n",
    "\n",
    "    \n",
    "    logging.info(\"Grabbing: \"+row[\"quelldatei\"])\n",
    "\n",
    "    print(tmpdatafile)\n",
    "    print(plotfile)\n",
    "\n",
    "    #StockscreenerWinners_stats.cleardir(tmpdatafile)\n",
    "    #StockscreenerWinners_stats.cleardir(plotfile)\n",
    "\n",
    "    \n",
    "    true_tickers=[]\n",
    "    true_names = []\n",
    "    true_industry = []\n",
    "    true_sector = []\n",
    "    true_marketCap =[]\n",
    "    shit_list = []\n",
    "    \n",
    "    \n",
    "    ################### Anzahl Balken, also Handelstage !\n",
    "    xxs = 5\n",
    "    xs = 10\n",
    "    s = 21\n",
    "    m=50\n",
    "\n",
    "\n",
    "    ####################################################\n",
    "    ## HIer die Anzhal dr Kalendertage\n",
    "    xxs_d = xxs + 2\n",
    "    xs_d= xs + 4\n",
    "    s_d = s + 8\n",
    "    m_d = m + 20\n",
    "    l_d = ll + 24\n",
    "    \n",
    "    \n",
    "    \n",
    "    Anz = -1 \n",
    "    shitflag = False\n",
    "    while Anz <  Anzahl:\n",
    "        Anz=Anz+1\n",
    "        #print(\"################################\")\n",
    "        #print(\"Anzhal Wochen: \", Anz)\n",
    "        #print(\"################################\")\n",
    "        #end_date = enddatum \n",
    "         \n",
    "        #### End_date: Letztes Dtaum der Zeitreihe der Preise !\n",
    "        end_date = datetime.date.today()\n",
    "        end_date = end_date - datetime.timedelta(days=7*Anz)\n",
    "        bis = end_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        #### Start_date: Start der Zeitreihe der Preise in der Vergangeheit\n",
    "        dAll = l_d + 2 \n",
    "        start_date =  end_date - datetime.timedelta(days=dAll)\n",
    "        von = start_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        start_l = end_date - datetime.timedelta(days=l_d)\n",
    "        if start_l.weekday() == 5:\n",
    "            start_l=start_l -  datetime.timedelta(days=1)\n",
    "        if start_l.weekday() == 6:\n",
    "            start_l=start_l +  datetime.timedelta(days=1)\n",
    "        \n",
    "        start_m = end_date - datetime.timedelta(days=m_d)\n",
    "        if start_m.weekday() == 5:\n",
    "            start_m=start_m -  datetime.timedelta(days=1)\n",
    "        if start_m.weekday() == 6:\n",
    "            start_m=start_m +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_s = end_date - datetime.timedelta(days=s_d)\n",
    "        if start_s.weekday() == 5:\n",
    "            start_s=start_s -  datetime.timedelta(days=1)\n",
    "        if start_s.weekday() == 6:\n",
    "            start_s=start_s +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xs = end_date - datetime.timedelta(days=xs_d)\n",
    "        if start_xs.weekday() == 5:\n",
    "            start_xs=start_xs -  datetime.timedelta(days=1)\n",
    "        if start_xs.weekday() == 6:\n",
    "            start_xs=start_xs +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xxs = end_date - datetime.timedelta(days=xxs_d)\n",
    "        if start_xxs.weekday() == 5:\n",
    "            start_xxs=start_xxs -  datetime.timedelta(days=1)\n",
    "        if start_xxs.weekday() == 6:\n",
    "            start_xxs=start_xxs +  datetime.timedelta(days=1)\n",
    "        \n",
    "        all_dates = [start_l,start_m,start_s,start_xs,start_xxs]\n",
    "        \n",
    "        \n",
    "        # in form von strings:\n",
    "        \n",
    "        \n",
    "        \n",
    "        Zeitstempel= bis + \"__\" + von\n",
    "\n",
    "    \n",
    "        # S&P Index Returns\n",
    "        \n",
    "        counter =-1\n",
    "       \n",
    "        for ticker in stock:\n",
    "            df = pd.DataFrame()\n",
    "            print(ticker)\n",
    "\n",
    "            counter=counter+1\n",
    "            \n",
    "            # name des ETFs:\n",
    "            # Download abber_stats.historical data as CSV for each stock (makes the process faster)\n",
    "            sthwrong=True\n",
    "           \n",
    "            time.sleep(0.4)\n",
    "            oo = yf.Ticker(ticker)\n",
    "            print(oo)\n",
    "            time.sleep(0.4)  \n",
    "        #   df = yf.download(ticker, start=start_date.strftime(\"%Y-%m-%d\"), end=end_date.strftime(\"%Y-%m-%d\"))\n",
    "            try:\n",
    "                name = ticker\n",
    "                df = oo.history(periode)    \n",
    "            \n",
    "\n",
    "            except:\n",
    "                print(f\"{ticker}, {name}: korrupt. Keine History\")\n",
    "            try:\n",
    "                #print(\"name:\", name)\n",
    "                print(oo.info[\"longName\"])\n",
    "                name = oo.info[\"longName\"]\n",
    "            except:\n",
    "                print(f\"{ticker}: korrupt. Kein Longname\")\n",
    "            try:\n",
    "                    industry = oo.info[\"industry\"]\n",
    "                    sector = oo.info[\"sector\"]\n",
    "                    marketCap = int(oo.info[\"marketCap\"]/1000000000)\n",
    "                    print(industry,\"/\",sector,\"/\",marketCap, \"bln.$\")\n",
    "                    \n",
    "            except:\n",
    "                    industry=\"ETF\"    \n",
    "                    sector = \"sector\"\n",
    "                    marketCap=1\n",
    "             \n",
    "\n",
    "            if (len(df) < ll - 8) or ((end_date - df.index[-1].date()).days > 3 ):\n",
    "                l = len(df)\n",
    "                if l>0 :\n",
    "                    dt = str((end_date -  df.index[-1].date()).days)\n",
    "                else:\n",
    "                    dt = \"NaN\"\n",
    "                print(ticker, \" : On shit_list !\" )\n",
    "                print(\"date: \"+ str(end_date) + \" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name)+\"\\n\")\n",
    "                shit_list.append(ticker+\":\"+\" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name))\n",
    "            \n",
    "            if (len(df) >= ll - 8) and ((end_date -  df.index[-1].date()).days <= 3 ):\n",
    "                ## Checke, ob genug taeglioch Datensaetze geladne wurdne, um geforderte Historei zu analysieren\n",
    "                #long_date,middle_date, short_date,last_date = checkdate(df)\n",
    "                true_tickers.append(ticker)  \n",
    "                #tbiontrue names benennt die ticker, die tatsaechlich Daten lieferten.\n",
    "                true_names.append(name)  \n",
    "                true_industry.append(industry)  \n",
    "                true_sector.append(sector)\n",
    "                true_marketCap.append(marketCap)\n",
    "            \n",
    "                # Calculating returns relative to the market (returns multiple)\n",
    "                # fuer die letzen >>LaengeReturnHistorie<< Tage\n",
    "                df['Percent Change'] = df['Close'].pct_change()\n",
    "                df['Factor'] =  (df['Percent Change'] + 1).cumprod()\n",
    "                \n",
    "                stock_return = df['Factor'][-1]\n",
    "\n",
    "                df=Indikatoren.ATR(df,20)\n",
    "                df[\"EMA50\"]=df[\"Factor\"].ewm(span=50,adjust=False).mean()\n",
    "                df[\"EMA10\"]=df[\"Factor\"].ewm(span=10,adjust=False).mean()\n",
    "                df[\"EMA21\"]=df[\"Factor\"].ewm(span=21,adjust=False).mean()\n",
    "                df[\"EMA100\"]=df[\"Factor\"].ewm(span=100,adjust=False).mean()\n",
    "                df[\"EMA80\"]=df[\"Factor\"].ewm(span=80,adjust=False).mean()\n",
    "                df[\"EMA200\"]=df[\"Factor\"].ewm(span=200,adjust=False).mean()\n",
    "\n",
    "                df[\"momentum\"]=df[\"Factor\"]-df[\"EMA10\"]+df[\"EMA21\"] -df[\"EMA50\"] +df[\"EMA100\"]-df[\"EMA200\"]\n",
    "                \n",
    "                Indikatoren.MACD(df, 12, 26,9,\"_day\")\n",
    "                Indikatoren.MACD(df, 60, 130,45,\"_week\")    \n",
    "                \n",
    "\n",
    "                returns_multiple = 100*round(stock_return-1.0, 4)\n",
    "                print (f'Ticker: {ticker}; Returns Multiple: {returns_multiple:.2f} %\\n')\n",
    "                df.to_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', float_format='%.5f',)               \n",
    "            ## schreibe Ticker und die Longnames raus !\n",
    "            _ticker_names = pd.DataFrame(list(zip(true_tickers,true_names,true_industry,true_sector,true_marketCap)),\n",
    "                            columns=['ticker','name','industry',\"sector\",\"marketCap\"])\n",
    "            _ticker_names = _ticker_names.sort_values(\"ticker\")               \n",
    "            _ticker_names.to_csv(tmpdatafile +\"//\"+ \"_ticker_names.csv\",sep=\";\")  \n",
    "        \n",
    "        if shitflag==False:\n",
    "            shitflag = True    \n",
    "            shit_file = open(resfile+\"//\"+\"_shit\"+'.csv','w')\n",
    "            for item in shit_list:\n",
    "                shit_file.write(item+\"\\n\")\n",
    "            shit_file.close()    \n",
    "\n",
    "print(\"Done so far. This is what has been written to the csv..: \\n\\n\")\n",
    "df = pd.read_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', \n",
    "                            parse_dates=True,\n",
    "                            index_col=0)\n",
    "print(df.head(5))\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(df.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1eeed662d4e0aec0daec9fbef0f4bebea6e5a88731d55a40c66e53b57018d805"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 32-bit ('DataGrabber': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
