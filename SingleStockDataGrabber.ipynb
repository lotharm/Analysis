{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets HighOpenLowClose Data of a single stock\n",
    "This Noteboock extracts HOLC Data from Yahoo finance and writes it into a csv file on drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOCK \n",
    "Name the Stock by entering the ticker symbol\n",
    "$\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock = [\"YPF\",]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run that Celle and that is it ...\n",
    "Watch out for the output at the bottom. Check if this is the stock and the data you actually want to see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quellpfad': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS'], 'quelldatei': ['macro'], 'plotdir': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS\\\\Analyse_data'], 'resdir': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS\\\\Analyse_data'], 'vamsdir': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS\\\\Analyse_data'], 'tmpdatadir': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS\\\\Analyse_data']}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 28 13:21:14 2021\n",
    "\n",
    "@author: Schroeder\n",
    "\"\"\"\n",
    "#https://www.dividendenadel.de/indexmonitor-maerz-2021/\n",
    "#zykliker: Chemie , rohstoofe (spaet im zyklus)Bauträger, Maschiennebau, REITS, Banken, Versicheurngen, Autobauer, ReisenHotels, Kreuztfahreten\n",
    "#Antizyklishc/Defneisv: telekom, nestle, Metro,\n",
    "import os\n",
    "import sys\n",
    "\n",
    "###### Insert the following three lines to make any import lib in he project dir setup visible to an other\n",
    "###### Directory in the project setup\n",
    "\n",
    "currentdir = os.path.abspath('')\n",
    "parentdir = os.path.realpath(os.path.join(currentdir, '..'))\n",
    "sys.path.insert(0, parentdir) \n",
    "#############################################################\n",
    "\n",
    "from MomentumScreening import my_setup\n",
    "###\n",
    "### The whole /ETFS/ Tree has to be located on ame level as repository \n",
    "pfad = os.path.realpath(os.path.join(parentdir, 'ETFS'))\n",
    "logpfad = os.path.realpath(os.path.join(parentdir, 'LOG'))\n",
    "##########################################################################\n",
    "mypath = os.path.realpath(os.path.join(pfad, my_setup.specific_datapath)) \n",
    "\n",
    "output_path = mypath\n",
    "\n",
    "\n",
    "keyword = \"macro\"\n",
    "\n",
    "Universe = {'quellpfad':[pfad],\n",
    "            'quelldatei': [keyword], \n",
    "            'plotdir':[mypath],\n",
    "            'resdir':[mypath],\n",
    "            'vamsdir':[mypath],\n",
    "            'tmpdatadir':[mypath],\n",
    "            } \n",
    "\n",
    "\n",
    "Anzahl = 0 \n",
    "\n",
    "periode = \"15y\"\n",
    "ll=600\n",
    "\n",
    "\n",
    "print(Universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\Trading\\ETFS\\Analyse_data\n",
      "C:\\Users\\Michael\\Trading\\ETFS\\Analyse_data\n",
      "YPF\n",
      "yfinance.Ticker object <YPF>\n",
      "YPF Sociedad Anónima\n",
      "Oil & Gas Integrated / Energy / 2 bln.$\n",
      "Ticker: YPF; Returns Multiple: -69.41 %\n",
      "\n",
      "Done so far. This is what has been written to the csv..: \n",
      "\n",
      "\n",
      "                Open      High       Low     Close  Volume  Dividends  \\\n",
      "Date                                                                    \n",
      "2007-09-10  23.75107  23.84301  22.49456  22.77038   16700        0.0   \n",
      "2007-09-11  23.10749  23.16878  21.95517  22.43326   40500        0.0   \n",
      "2007-09-12  22.53747  23.42009  22.40262  23.15652   16800        0.0   \n",
      "2007-09-13  23.29137  23.44460  23.13814  23.29137   10100        0.0   \n",
      "2007-09-14  23.04620  23.24234  22.72748  22.98491    9300        0.0   \n",
      "\n",
      "            Stock Splits  Percent Change   Factor  ATR20  ...   EMA100  \\\n",
      "Date                                                      ...            \n",
      "2007-09-10             0             NaN      NaN    NaN  ...      NaN   \n",
      "2007-09-11             0        -0.01481  0.98519    NaN  ...  0.98519   \n",
      "2007-09-12             0         0.03224  1.01696    NaN  ...  0.98582   \n",
      "2007-09-13             0         0.00582  1.02288    NaN  ...  0.98656   \n",
      "2007-09-14             0        -0.01316  1.00942    NaN  ...  0.98701   \n",
      "\n",
      "              EMA80   EMA200  momentum  MACD_day  MACDsign_day  MACDdif_day  \\\n",
      "Date                                                                          \n",
      "2007-09-10      NaN      NaN       NaN   0.00000       0.00000      0.00000   \n",
      "2007-09-11  0.98519  0.98519   0.00000  -0.02689      -0.01494     -0.01195   \n",
      "2007-09-12  0.98598  0.98551   0.02794   0.01004      -0.00470      0.01474   \n",
      "2007-09-13  0.98689  0.98588   0.03016   0.04962       0.01370      0.03592   \n",
      "2007-09-14  0.98745  0.98612   0.01543   0.05561       0.02617      0.02945   \n",
      "\n",
      "            MACD_week  MACDsign_week  MACDdif_week  \n",
      "Date                                                \n",
      "2007-09-10    0.00000        0.00000       0.00000  \n",
      "2007-09-11   -0.00591       -0.00302      -0.00289  \n",
      "2007-09-12    0.00114       -0.00157       0.00271  \n",
      "2007-09-13    0.01022        0.00158       0.00864  \n",
      "2007-09-14    0.01349        0.00418       0.00931  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "-------------------------------------------------------------------\n",
      "            Open  High   Low  Close   Volume  Dividends  Stock Splits  \\\n",
      "Date                                                                    \n",
      "2022-09-02  5.71  5.96  5.56  5.820  2965000        0.0             0   \n",
      "2022-09-06  5.95  6.25  5.76  6.020  4113200        0.0             0   \n",
      "2022-09-07  5.95  6.64  5.77  6.600  5437700        0.0             0   \n",
      "2022-09-08  6.74  7.04  6.61  6.770  5528200        0.0             0   \n",
      "2022-09-09  6.74  7.00  6.90  6.965   172218        0.0             0   \n",
      "\n",
      "            Percent Change   Factor    ATR20  ...   EMA100    EMA80   EMA200  \\\n",
      "Date                                          ...                              \n",
      "2022-09-02         0.03559  0.25560  0.34404  ...  0.18514  0.18636  0.18642   \n",
      "2022-09-06         0.03436  0.26438  0.35794  ...  0.18671  0.18828  0.18720   \n",
      "2022-09-07         0.09635  0.28985  0.40671  ...  0.18876  0.19079  0.18822   \n",
      "2022-09-08         0.02576  0.29732  0.40988  ...  0.19091  0.19342  0.18931   \n",
      "2022-09-09         0.02880  0.30588  0.39275  ...  0.19318  0.19620  0.19047   \n",
      "\n",
      "            momentum  MACD_day  MACDsign_day  MACDdif_day  MACD_week  \\\n",
      "Date                                                                   \n",
      "2022-09-02   0.04133   0.53105       0.48169      0.04936    0.10824   \n",
      "2022-09-06   0.04755   0.54677       0.49471      0.05206    0.13643   \n",
      "2022-09-07   0.06796   0.59912       0.51559      0.08353    0.17339   \n",
      "2022-09-08   0.07058   0.64687       0.54184      0.10502    0.21147   \n",
      "2022-09-09   0.07433   0.69246       0.57197      0.12049    0.25106   \n",
      "\n",
      "            MACDsign_week  MACDdif_week  \n",
      "Date                                     \n",
      "2022-09-02       -0.13283       0.24106  \n",
      "2022-09-06       -0.12112       0.25756  \n",
      "2022-09-07       -0.10832       0.28170  \n",
      "2022-09-08       -0.09441       0.30588  \n",
      "2022-09-09       -0.07939       0.33045  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#https://www.tradingview.com/x/RHiQkrp0/\n",
    "\n",
    "\n",
    "quantil = 0.1\n",
    "riskquantil = 0.00005\n",
    "\n",
    "\n",
    "SingleEMAperiod = 50\n",
    "BenchmarkEMAperiod = 100\n",
    "#das Fenster um die Regression zu rechnen:\n",
    "roll_window = 60\n",
    "\n",
    "Num_of_positions = 10\n",
    "CutOff_positions = 20\n",
    "\n",
    "#desktoppfad = 'C:/Users/_schr/Desktop/'\n",
    "desktoppfad = output_path\n",
    "\n",
    "\n",
    "benchmarkfile = \"SPY.csv\"\n",
    "\n",
    "def figures_to_html(figs, filename=\"dashboard.html\"):\n",
    "    dashboard = open(filename, 'w')\n",
    "    dashboard.write(\"<html><head></head><body>\" + \"\\n\")\n",
    "    for fig in figs:\n",
    "        inner_html = fig.to_html().split('<body>')[1].split('</body>')[0]\n",
    "        dashboard.write(inner_html)\n",
    "    dashboard.write(\"</body></html>\" + \"\\n\")\n",
    "\n",
    "\n",
    "# Liest ETF historien von yahoo finance aus und macth ein ranking.\n",
    "\n",
    "\n",
    "\n",
    "from MomentumScreening import TickerSelector, regression, StockscreenerWinners_stats\n",
    "from lib import Indikatoren\n",
    "\n",
    " \n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import calendar\n",
    "\n",
    "\n",
    "# Imports\n",
    "from pandas_datareader import data as pdr\n",
    "#from yahoo_fin import stock_info as si\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "import os.path\n",
    "\n",
    "\n",
    "#lieferrt bei gegebenem datatfram mit datum als index das erste Datum, das letzte, und zwei \n",
    "# dazwischen \n",
    "\n",
    "\n",
    "def sort_final(liste):\n",
    "    liste[\"rang\"]= 0.1*liste[str(m)+\"d_rs\"]+0.9*liste[str(ll)+\"d_rs\"]\n",
    "    liste[\"ranking\"]=liste.rang.rank()\n",
    "\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "\n",
    "universe = pd.DataFrame(Universe)\n",
    "\n",
    "if my_setup.logger == \"On\":\n",
    "    fname = logpfad + \"\\\\\" + str(datetime.datetime.now().day)+ \"--\"+str(datetime.datetime.now().hour)+\"-\"+ str(datetime.datetime.now().minute)+\".log\"\n",
    "    logging.basicConfig(filename=fname,\n",
    "                        format=\"%(asctime)s %(message)s\", \n",
    "                        datefmt=\"%m/%d %I:%M:%S %p\", \n",
    "                    level=logging.INFO)  \n",
    "\n",
    "logging.info(\"Start DataGrabbing\")\n",
    "\n",
    "for index, row in universe.iterrows():\n",
    "    tickerfile = row[\"quellpfad\"]+row[\"quelldatei\"]+\".csv\"\n",
    "    plotfile = row[\"plotdir\"]\n",
    "    resfile =  row[\"resdir\"]\n",
    "    tmpdatafile = row[\"tmpdatadir\"]\n",
    "    vamsfile = row[\"vamsdir\"]\n",
    "\n",
    "    \n",
    "    logging.info(\"Grabbing: \"+row[\"quelldatei\"])\n",
    "\n",
    "    print(tmpdatafile)\n",
    "    print(plotfile)\n",
    "\n",
    "    #StockscreenerWinners_stats.cleardir(tmpdatafile)\n",
    "    #StockscreenerWinners_stats.cleardir(plotfile)\n",
    "\n",
    "    \n",
    "    true_tickers=[]\n",
    "    true_names = []\n",
    "    true_industry = []\n",
    "    true_sector = []\n",
    "    true_marketCap =[]\n",
    "    shit_list = []\n",
    "    \n",
    "    \n",
    "    ################### Anzahl Balken, also Handelstage !\n",
    "    xxs = 5\n",
    "    xs = 10\n",
    "    s = 21\n",
    "    m=50\n",
    "\n",
    "\n",
    "    ####################################################\n",
    "    ## HIer die Anzhal dr Kalendertage\n",
    "    xxs_d = xxs + 2\n",
    "    xs_d= xs + 4\n",
    "    s_d = s + 8\n",
    "    m_d = m + 20\n",
    "    l_d = ll + 24\n",
    "    \n",
    "    \n",
    "    \n",
    "    Anz = -1 \n",
    "    shitflag = False\n",
    "    while Anz <  Anzahl:\n",
    "        Anz=Anz+1\n",
    "        #print(\"################################\")\n",
    "        #print(\"Anzhal Wochen: \", Anz)\n",
    "        #print(\"################################\")\n",
    "        #end_date = enddatum \n",
    "         \n",
    "        #### End_date: Letztes Dtaum der Zeitreihe der Preise !\n",
    "        end_date = datetime.date.today()\n",
    "        end_date = end_date - datetime.timedelta(days=7*Anz)\n",
    "        bis = end_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        #### Start_date: Start der Zeitreihe der Preise in der Vergangeheit\n",
    "        dAll = l_d + 2 \n",
    "        start_date =  end_date - datetime.timedelta(days=dAll)\n",
    "        von = start_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        start_l = end_date - datetime.timedelta(days=l_d)\n",
    "        if start_l.weekday() == 5:\n",
    "            start_l=start_l -  datetime.timedelta(days=1)\n",
    "        if start_l.weekday() == 6:\n",
    "            start_l=start_l +  datetime.timedelta(days=1)\n",
    "        \n",
    "        start_m = end_date - datetime.timedelta(days=m_d)\n",
    "        if start_m.weekday() == 5:\n",
    "            start_m=start_m -  datetime.timedelta(days=1)\n",
    "        if start_m.weekday() == 6:\n",
    "            start_m=start_m +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_s = end_date - datetime.timedelta(days=s_d)\n",
    "        if start_s.weekday() == 5:\n",
    "            start_s=start_s -  datetime.timedelta(days=1)\n",
    "        if start_s.weekday() == 6:\n",
    "            start_s=start_s +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xs = end_date - datetime.timedelta(days=xs_d)\n",
    "        if start_xs.weekday() == 5:\n",
    "            start_xs=start_xs -  datetime.timedelta(days=1)\n",
    "        if start_xs.weekday() == 6:\n",
    "            start_xs=start_xs +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xxs = end_date - datetime.timedelta(days=xxs_d)\n",
    "        if start_xxs.weekday() == 5:\n",
    "            start_xxs=start_xxs -  datetime.timedelta(days=1)\n",
    "        if start_xxs.weekday() == 6:\n",
    "            start_xxs=start_xxs +  datetime.timedelta(days=1)\n",
    "        \n",
    "        all_dates = [start_l,start_m,start_s,start_xs,start_xxs]\n",
    "        \n",
    "        \n",
    "        # in form von strings:\n",
    "        \n",
    "        \n",
    "        \n",
    "        Zeitstempel= bis + \"__\" + von\n",
    "\n",
    "    \n",
    "        # S&P Index Returns\n",
    "        \n",
    "        counter =-1\n",
    "       \n",
    "        for ticker in stock:\n",
    "            df = pd.DataFrame()\n",
    "            print(ticker)\n",
    "\n",
    "            counter=counter+1\n",
    "            \n",
    "            # name des ETFs:\n",
    "            # Download abber_stats.historical data as CSV for each stock (makes the process faster)\n",
    "            sthwrong=True\n",
    "           \n",
    "            time.sleep(0.4)\n",
    "            oo = yf.Ticker(ticker)\n",
    "            print(oo)\n",
    "            time.sleep(0.4)  \n",
    "        #   df = yf.download(ticker, start=start_date.strftime(\"%Y-%m-%d\"), end=end_date.strftime(\"%Y-%m-%d\"))\n",
    "            try:\n",
    "                name = ticker\n",
    "                df = oo.history(periode)    \n",
    "            \n",
    "\n",
    "            except:\n",
    "                print(f\"{ticker}, {name}: korrupt. Keine History\")\n",
    "            try:\n",
    "                #print(\"name:\", name)\n",
    "                print(oo.info[\"longName\"])\n",
    "                name = oo.info[\"longName\"]\n",
    "            except:\n",
    "                print(f\"{ticker}: korrupt. Kein Longname\")\n",
    "            try:\n",
    "                    industry = oo.info[\"industry\"]\n",
    "                    sector = oo.info[\"sector\"]\n",
    "                    marketCap = int(oo.info[\"marketCap\"]/1000000000)\n",
    "                    print(industry,\"/\",sector,\"/\",marketCap, \"bln.$\")\n",
    "                    \n",
    "            except:\n",
    "                    industry=\"ETF\"    \n",
    "                    sector = \"sector\"\n",
    "                    marketCap=1\n",
    "             \n",
    "\n",
    "            if (len(df) < ll - 8) or ((end_date - df.index[-1].date()).days > 3 ):\n",
    "                l = len(df)\n",
    "                if l>0 :\n",
    "                    dt = str((end_date -  df.index[-1].date()).days)\n",
    "                else:\n",
    "                    dt = \"NaN\"\n",
    "                print(ticker, \" : On shit_list !\" )\n",
    "                print(\"date: \"+ str(end_date) + \" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name)+\"\\n\")\n",
    "                shit_list.append(ticker+\":\"+\" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name))\n",
    "            \n",
    "            if (len(df) >= ll - 8) and ((end_date -  df.index[-1].date()).days <= 3 ):\n",
    "                ## Checke, ob genug taeglioch Datensaetze geladne wurdne, um geforderte Historei zu analysieren\n",
    "                #long_date,middle_date, short_date,last_date = checkdate(df)\n",
    "                true_tickers.append(ticker)  \n",
    "                #tbiontrue names benennt die ticker, die tatsaechlich Daten lieferten.\n",
    "                true_names.append(name)  \n",
    "                true_industry.append(industry)  \n",
    "                true_sector.append(sector)\n",
    "                true_marketCap.append(marketCap)\n",
    "            \n",
    "                # Calculating returns relative to the market (returns multiple)\n",
    "                # fuer die letzen >>LaengeReturnHistorie<< Tage\n",
    "                df['Percent Change'] = df['Close'].pct_change()\n",
    "                df['Factor'] =  (df['Percent Change'] + 1).cumprod()\n",
    "                \n",
    "                stock_return = df['Factor'][-1]\n",
    "\n",
    "                df=Indikatoren.ATR(df,20)\n",
    "                df[\"EMA50\"]=df[\"Factor\"].ewm(span=50,adjust=False).mean()\n",
    "                df[\"EMA10\"]=df[\"Factor\"].ewm(span=10,adjust=False).mean()\n",
    "                df[\"EMA21\"]=df[\"Factor\"].ewm(span=21,adjust=False).mean()\n",
    "                df[\"EMA100\"]=df[\"Factor\"].ewm(span=100,adjust=False).mean()\n",
    "                df[\"EMA80\"]=df[\"Factor\"].ewm(span=80,adjust=False).mean()\n",
    "                df[\"EMA200\"]=df[\"Factor\"].ewm(span=200,adjust=False).mean()\n",
    "\n",
    "                df[\"momentum\"]=df[\"Factor\"]-df[\"EMA10\"]+df[\"EMA21\"] -df[\"EMA50\"] +df[\"EMA100\"]-df[\"EMA200\"]\n",
    "                \n",
    "                Indikatoren.MACD(df, 12, 26,9,\"_day\")\n",
    "                Indikatoren.MACD(df, 60, 130,45,\"_week\")    \n",
    "                \n",
    "\n",
    "                returns_multiple = 100*round(stock_return-1.0, 4)\n",
    "                print (f'Ticker: {ticker}; Returns Multiple: {returns_multiple:.2f} %\\n')\n",
    "                df.to_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', float_format='%.5f',)               \n",
    "            ## schreibe Ticker und die Longnames raus !\n",
    "            _ticker_names = pd.DataFrame(list(zip(true_tickers,true_names,true_industry,true_sector,true_marketCap)),\n",
    "                            columns=['ticker','name','industry',\"sector\",\"marketCap\"])\n",
    "            _ticker_names = _ticker_names.sort_values(\"ticker\")               \n",
    "            _ticker_names.to_csv(tmpdatafile +\"//\"+ \"_ticker_names.csv\",sep=\";\")  \n",
    "        \n",
    "        if shitflag==False:\n",
    "            shitflag = True    \n",
    "            shit_file = open(resfile+\"//\"+\"_shit\"+'.csv','w')\n",
    "            for item in shit_list:\n",
    "                shit_file.write(item+\"\\n\")\n",
    "            shit_file.close()    \n",
    "\n",
    "print(\"Done so far. This is what has been written to the csv..: \\n\\n\")\n",
    "df = pd.read_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', \n",
    "                            parse_dates=True,\n",
    "                            index_col=0)\n",
    "print(df.head(5))\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(df.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
