{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets HighOpenLowClose Data of a single stock\n",
    "This Noteboock extracts HOLC Data from Yahoo finance and writes it into a csv file on drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOCK \n",
    "Name the Stock by entering the ticker symbol\n",
    "$\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock = [\"CGAU\",]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run that Celle and that is it ...\n",
    "Watch out for the output at the bottom. Check if this is the stock and the data you actually want to see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quellpfad': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS'], 'quelldatei': ['macro'], 'plotdir': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS\\\\Analyse_data'], 'resdir': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS\\\\Analyse_data'], 'vamsdir': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS\\\\Analyse_data'], 'tmpdatadir': ['C:\\\\Users\\\\Michael\\\\Trading\\\\ETFS\\\\Analyse_data']}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 28 13:21:14 2021\n",
    "\n",
    "@author: Schroeder\n",
    "\"\"\"\n",
    "#https://www.dividendenadel.de/indexmonitor-maerz-2021/\n",
    "#zykliker: Chemie , rohstoofe (spaet im zyklus)Bautr√§ger, Maschiennebau, REITS, Banken, Versicheurngen, Autobauer, ReisenHotels, Kreuztfahreten\n",
    "#Antizyklishc/Defneisv: telekom, nestle, Metro,\n",
    "import os\n",
    "import sys\n",
    "\n",
    "###### Insert the following three lines to make any import lib in he project dir setup visible to an other\n",
    "###### Directory in the project setup\n",
    "\n",
    "currentdir = os.path.abspath('')\n",
    "parentdir = os.path.realpath(os.path.join(currentdir, '..'))\n",
    "sys.path.insert(0, parentdir) \n",
    "#############################################################\n",
    "\n",
    "from MomentumScreening import my_setup\n",
    "###\n",
    "### The whole /ETFS/ Tree has to be located on ame level as repository \n",
    "pfad = os.path.realpath(os.path.join(parentdir, 'ETFS'))\n",
    "logpfad = os.path.realpath(os.path.join(parentdir, 'LOG'))\n",
    "##########################################################################\n",
    "mypath = os.path.realpath(os.path.join(pfad, my_setup.specific_datapath)) \n",
    "\n",
    "output_path = mypath\n",
    "\n",
    "\n",
    "keyword = \"macro\"\n",
    "\n",
    "Universe = {'quellpfad':[pfad],\n",
    "            'quelldatei': [keyword], \n",
    "            'plotdir':[mypath],\n",
    "            'resdir':[mypath],\n",
    "            'vamsdir':[mypath],\n",
    "            'tmpdatadir':[mypath],\n",
    "            } \n",
    "\n",
    "\n",
    "Anzahl = 0 \n",
    "\n",
    "periode = \"15y\"\n",
    "ll=600\n",
    "\n",
    "\n",
    "print(Universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\Trading\\ETFS\\Analyse_data\n",
      "C:\\Users\\Michael\\Trading\\ETFS\\Analyse_data\n",
      "CGAU\n",
      "yfinance.Ticker object <CGAU>\n",
      "Centerra Gold Inc.\n",
      "Gold / Basic Materials / 1 bln.$\n",
      "Ticker: CGAU; Returns Multiple: -9.48 %\n",
      "\n",
      "Done so far. This is what has been written to the csv..: \n",
      "\n",
      "\n",
      "               Open     High      Low    Close  Volume  Dividends  \\\n",
      "Date                                                                \n",
      "2008-06-24  5.08161  5.08161  5.08161  5.08161       0        0.0   \n",
      "2008-06-26  4.95284  4.95284  4.95284  4.95284    2000        0.0   \n",
      "2008-06-27  4.94293  5.03208  4.94293  4.94293   10700        0.0   \n",
      "2008-06-30  4.94293  4.94293  4.94293  4.94293       0        0.0   \n",
      "2008-07-03  3.93255  4.20991  3.91274  3.93255   15000        0.0   \n",
      "\n",
      "            Stock Splits  Percent Change   Factor  ATR20  ...   EMA100  \\\n",
      "Date                                                      ...            \n",
      "2008-06-24             0             NaN      NaN    NaN  ...      NaN   \n",
      "2008-06-26             0        -0.02534  0.97466    NaN  ...  0.97466   \n",
      "2008-06-27             0        -0.00200  0.97271    NaN  ...  0.97462   \n",
      "2008-06-30             0         0.00000  0.97271    NaN  ...  0.97458   \n",
      "2008-07-03             0        -0.20441  0.77388    NaN  ...  0.97061   \n",
      "\n",
      "              EMA80   EMA200  momentum  MACD_day  MACDsign_day  MACDdif_day  \\\n",
      "Date                                                                          \n",
      "2008-06-24      NaN      NaN       NaN   0.00000       0.00000      0.00000   \n",
      "2008-06-26  0.97466  0.97466   0.00000  -0.01027      -0.00571     -0.00457   \n",
      "2008-06-27  0.97461  0.97464  -0.00171  -0.01899      -0.01115     -0.00784   \n",
      "2008-06-30  0.97456  0.97462  -0.00153  -0.02561      -0.01605     -0.00956   \n",
      "2008-07-03  0.96961  0.97262  -0.17630  -0.11110      -0.04433     -0.06678   \n",
      "\n",
      "            MACD_week  MACDsign_week  MACDdif_week  \n",
      "Date                                                \n",
      "2008-06-24    0.00000        0.00000       0.00000  \n",
      "2008-06-26   -0.00226       -0.00115      -0.00110  \n",
      "2008-06-27   -0.00458       -0.00235      -0.00223  \n",
      "2008-06-30   -0.00679       -0.00353      -0.00326  \n",
      "2008-07-03   -0.02659       -0.00856      -0.01803  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "-------------------------------------------------------------------\n",
      "            Open  High   Low  Close  Volume  Dividends  Stock Splits  \\\n",
      "Date                                                                   \n",
      "2022-08-15  5.17  5.17  4.89   4.93  227500        0.0             0   \n",
      "2022-08-16  4.91  4.94  4.81   4.88  129800        0.0             0   \n",
      "2022-08-17  4.82  4.83  4.65   4.72  131900        0.0             0   \n",
      "2022-08-18  4.70  4.81  4.66   4.67  161000        0.0             0   \n",
      "2022-08-19  4.67  4.71  4.55   4.60  131800        0.0             0   \n",
      "\n",
      "            Percent Change   Factor    ATR20  ...   EMA100    EMA80   EMA200  \\\n",
      "Date                                          ...                              \n",
      "2022-08-15        -0.05010  0.97017  0.35027  ...  1.42093  1.37737  1.52692   \n",
      "2022-08-16        -0.01014  0.96033  0.32929  ...  1.41181  1.36708  1.52128   \n",
      "2022-08-17        -0.03279  0.92884  0.31983  ...  1.40225  1.35625  1.51539   \n",
      "2022-08-18        -0.01059  0.91900  0.30366  ...  1.39268  1.34546  1.50945   \n",
      "2022-08-19        -0.01499  0.90523  0.28998  ...  1.38303  1.33459  1.50344   \n",
      "\n",
      "            momentum  MACD_day  MACDsign_day  MACDdif_day  MACD_week  \\\n",
      "Date                                                                   \n",
      "2022-08-15  -0.35624  -0.34635      -0.25367     -0.09268   -0.75345   \n",
      "2022-08-16  -0.35013  -0.38162      -0.27926     -0.10236   -0.77376   \n",
      "2022-08-17  -0.36511  -0.41767      -0.30694     -0.11073   -0.79551   \n",
      "2022-08-18  -0.36064  -0.44514      -0.33458     -0.11056   -0.81671   \n",
      "2022-08-19  -0.36136  -0.46718      -0.36110     -0.10608   -0.83772   \n",
      "\n",
      "            MACDsign_week  MACDdif_week  \n",
      "Date                                     \n",
      "2022-08-15       -0.44497      -0.30848  \n",
      "2022-08-16       -0.45927      -0.31449  \n",
      "2022-08-17       -0.47389      -0.32163  \n",
      "2022-08-18       -0.48879      -0.32792  \n",
      "2022-08-19       -0.50396      -0.33376  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#https://www.tradingview.com/x/RHiQkrp0/\n",
    "\n",
    "\n",
    "quantil = 0.1\n",
    "riskquantil = 0.00005\n",
    "\n",
    "\n",
    "SingleEMAperiod = 50\n",
    "BenchmarkEMAperiod = 100\n",
    "#das Fenster um die Regression zu rechnen:\n",
    "roll_window = 60\n",
    "\n",
    "Num_of_positions = 10\n",
    "CutOff_positions = 20\n",
    "\n",
    "#desktoppfad = 'C:/Users/_schr/Desktop/'\n",
    "desktoppfad = output_path\n",
    "\n",
    "\n",
    "benchmarkfile = \"SPY.csv\"\n",
    "\n",
    "def figures_to_html(figs, filename=\"dashboard.html\"):\n",
    "    dashboard = open(filename, 'w')\n",
    "    dashboard.write(\"<html><head></head><body>\" + \"\\n\")\n",
    "    for fig in figs:\n",
    "        inner_html = fig.to_html().split('<body>')[1].split('</body>')[0]\n",
    "        dashboard.write(inner_html)\n",
    "    dashboard.write(\"</body></html>\" + \"\\n\")\n",
    "\n",
    "\n",
    "# Liest ETF historien von yahoo finance aus und macth ein ranking.\n",
    "\n",
    "\n",
    "\n",
    "from MomentumScreening import TickerSelector, regression, StockscreenerWinners_stats\n",
    "from lib import Indikatoren\n",
    "\n",
    " \n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import calendar\n",
    "\n",
    "\n",
    "# Imports\n",
    "from pandas_datareader import data as pdr\n",
    "#from yahoo_fin import stock_info as si\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "import os.path\n",
    "\n",
    "\n",
    "#lieferrt bei gegebenem datatfram mit datum als index das erste Datum, das letzte, und zwei \n",
    "# dazwischen \n",
    "\n",
    "\n",
    "def sort_final(liste):\n",
    "    liste[\"rang\"]= 0.1*liste[str(m)+\"d_rs\"]+0.9*liste[str(ll)+\"d_rs\"]\n",
    "    liste[\"ranking\"]=liste.rang.rank()\n",
    "\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "\n",
    "universe = pd.DataFrame(Universe)\n",
    "\n",
    "if my_setup.logger == \"On\":\n",
    "    fname = logpfad + \"\\\\\" + str(datetime.datetime.now().day)+ \"--\"+str(datetime.datetime.now().hour)+\"-\"+ str(datetime.datetime.now().minute)+\".log\"\n",
    "    logging.basicConfig(filename=fname,\n",
    "                        format=\"%(asctime)s %(message)s\", \n",
    "                        datefmt=\"%m/%d %I:%M:%S %p\", \n",
    "                    level=logging.INFO)  \n",
    "\n",
    "logging.info(\"Start DataGrabbing\")\n",
    "\n",
    "for index, row in universe.iterrows():\n",
    "    tickerfile = row[\"quellpfad\"]+row[\"quelldatei\"]+\".csv\"\n",
    "    plotfile = row[\"plotdir\"]\n",
    "    resfile =  row[\"resdir\"]\n",
    "    tmpdatafile = row[\"tmpdatadir\"]\n",
    "    vamsfile = row[\"vamsdir\"]\n",
    "\n",
    "    \n",
    "    logging.info(\"Grabbing: \"+row[\"quelldatei\"])\n",
    "\n",
    "    print(tmpdatafile)\n",
    "    print(plotfile)\n",
    "\n",
    "    #StockscreenerWinners_stats.cleardir(tmpdatafile)\n",
    "    #StockscreenerWinners_stats.cleardir(plotfile)\n",
    "\n",
    "    \n",
    "    true_tickers=[]\n",
    "    true_names = []\n",
    "    true_industry = []\n",
    "    true_sector = []\n",
    "    true_marketCap =[]\n",
    "    shit_list = []\n",
    "    \n",
    "    \n",
    "    ################### Anzahl Balken, also Handelstage !\n",
    "    xxs = 5\n",
    "    xs = 10\n",
    "    s = 21\n",
    "    m=50\n",
    "\n",
    "\n",
    "    ####################################################\n",
    "    ## HIer die Anzhal dr Kalendertage\n",
    "    xxs_d = xxs + 2\n",
    "    xs_d= xs + 4\n",
    "    s_d = s + 8\n",
    "    m_d = m + 20\n",
    "    l_d = ll + 24\n",
    "    \n",
    "    \n",
    "    \n",
    "    Anz = -1 \n",
    "    shitflag = False\n",
    "    while Anz <  Anzahl:\n",
    "        Anz=Anz+1\n",
    "        #print(\"################################\")\n",
    "        #print(\"Anzhal Wochen: \", Anz)\n",
    "        #print(\"################################\")\n",
    "        #end_date = enddatum \n",
    "         \n",
    "        #### End_date: Letztes Dtaum der Zeitreihe der Preise !\n",
    "        end_date = datetime.date.today()\n",
    "        end_date = end_date - datetime.timedelta(days=7*Anz)\n",
    "        bis = end_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        #### Start_date: Start der Zeitreihe der Preise in der Vergangeheit\n",
    "        dAll = l_d + 2 \n",
    "        start_date =  end_date - datetime.timedelta(days=dAll)\n",
    "        von = start_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        start_l = end_date - datetime.timedelta(days=l_d)\n",
    "        if start_l.weekday() == 5:\n",
    "            start_l=start_l -  datetime.timedelta(days=1)\n",
    "        if start_l.weekday() == 6:\n",
    "            start_l=start_l +  datetime.timedelta(days=1)\n",
    "        \n",
    "        start_m = end_date - datetime.timedelta(days=m_d)\n",
    "        if start_m.weekday() == 5:\n",
    "            start_m=start_m -  datetime.timedelta(days=1)\n",
    "        if start_m.weekday() == 6:\n",
    "            start_m=start_m +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_s = end_date - datetime.timedelta(days=s_d)\n",
    "        if start_s.weekday() == 5:\n",
    "            start_s=start_s -  datetime.timedelta(days=1)\n",
    "        if start_s.weekday() == 6:\n",
    "            start_s=start_s +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xs = end_date - datetime.timedelta(days=xs_d)\n",
    "        if start_xs.weekday() == 5:\n",
    "            start_xs=start_xs -  datetime.timedelta(days=1)\n",
    "        if start_xs.weekday() == 6:\n",
    "            start_xs=start_xs +  datetime.timedelta(days=1)\n",
    "            \n",
    "        start_xxs = end_date - datetime.timedelta(days=xxs_d)\n",
    "        if start_xxs.weekday() == 5:\n",
    "            start_xxs=start_xxs -  datetime.timedelta(days=1)\n",
    "        if start_xxs.weekday() == 6:\n",
    "            start_xxs=start_xxs +  datetime.timedelta(days=1)\n",
    "        \n",
    "        all_dates = [start_l,start_m,start_s,start_xs,start_xxs]\n",
    "        \n",
    "        \n",
    "        # in form von strings:\n",
    "        \n",
    "        \n",
    "        \n",
    "        Zeitstempel= bis + \"__\" + von\n",
    "\n",
    "    \n",
    "        # S&P Index Returns\n",
    "        \n",
    "        counter =-1\n",
    "       \n",
    "        for ticker in stock:\n",
    "            df = pd.DataFrame()\n",
    "            print(ticker)\n",
    "\n",
    "            counter=counter+1\n",
    "            \n",
    "            # name des ETFs:\n",
    "            # Download abber_stats.historical data as CSV for each stock (makes the process faster)\n",
    "            sthwrong=True\n",
    "           \n",
    "            time.sleep(0.4)\n",
    "            oo = yf.Ticker(ticker)\n",
    "            print(oo)\n",
    "            time.sleep(0.4)  \n",
    "        #   df = yf.download(ticker, start=start_date.strftime(\"%Y-%m-%d\"), end=end_date.strftime(\"%Y-%m-%d\"))\n",
    "            try:\n",
    "                name = ticker\n",
    "                df = oo.history(periode)    \n",
    "            \n",
    "\n",
    "            except:\n",
    "                print(f\"{ticker}, {name}: korrupt. Keine History\")\n",
    "            try:\n",
    "                #print(\"name:\", name)\n",
    "                print(oo.info[\"longName\"])\n",
    "                name = oo.info[\"longName\"]\n",
    "            except:\n",
    "                print(f\"{ticker}: korrupt. Kein Longname\")\n",
    "            try:\n",
    "                    industry = oo.info[\"industry\"]\n",
    "                    sector = oo.info[\"sector\"]\n",
    "                    marketCap = int(oo.info[\"marketCap\"]/1000000000)\n",
    "                    print(industry,\"/\",sector,\"/\",marketCap, \"bln.$\")\n",
    "                    \n",
    "            except:\n",
    "                    industry=\"ETF\"    \n",
    "                    sector = \"sector\"\n",
    "                    marketCap=1\n",
    "             \n",
    "\n",
    "            if (len(df) < ll - 8) or ((end_date - df.index[-1].date()).days > 3 ):\n",
    "                l = len(df)\n",
    "                if l>0 :\n",
    "                    dt = str((end_date -  df.index[-1].date()).days)\n",
    "                else:\n",
    "                    dt = \"NaN\"\n",
    "                print(ticker, \" : On shit_list !\" )\n",
    "                print(\"date: \"+ str(end_date) + \" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name)+\"\\n\")\n",
    "                shit_list.append(ticker+\":\"+\" Anzahl Tage:\"+str(l)+\" dt:\"+dt+\" | \"+str( name))\n",
    "            \n",
    "            if (len(df) >= ll - 8) and ((end_date -  df.index[-1].date()).days <= 3 ):\n",
    "                ## Checke, ob genug taeglioch Datensaetze geladne wurdne, um geforderte Historei zu analysieren\n",
    "                #long_date,middle_date, short_date,last_date = checkdate(df)\n",
    "                true_tickers.append(ticker)  \n",
    "                #tbiontrue names benennt die ticker, die tatsaechlich Daten lieferten.\n",
    "                true_names.append(name)  \n",
    "                true_industry.append(industry)  \n",
    "                true_sector.append(sector)\n",
    "                true_marketCap.append(marketCap)\n",
    "            \n",
    "                # Calculating returns relative to the market (returns multiple)\n",
    "                # fuer die letzen >>LaengeReturnHistorie<< Tage\n",
    "                df['Percent Change'] = df['Close'].pct_change()\n",
    "                df['Factor'] =  (df['Percent Change'] + 1).cumprod()\n",
    "                \n",
    "                stock_return = df['Factor'][-1]\n",
    "\n",
    "                df=Indikatoren.ATR(df,20)\n",
    "                df[\"EMA50\"]=df[\"Factor\"].ewm(span=50,adjust=False).mean()\n",
    "                df[\"EMA10\"]=df[\"Factor\"].ewm(span=10,adjust=False).mean()\n",
    "                df[\"EMA21\"]=df[\"Factor\"].ewm(span=21,adjust=False).mean()\n",
    "                df[\"EMA100\"]=df[\"Factor\"].ewm(span=100,adjust=False).mean()\n",
    "                df[\"EMA80\"]=df[\"Factor\"].ewm(span=80,adjust=False).mean()\n",
    "                df[\"EMA200\"]=df[\"Factor\"].ewm(span=200,adjust=False).mean()\n",
    "\n",
    "                df[\"momentum\"]=df[\"Factor\"]-df[\"EMA10\"]+df[\"EMA21\"] -df[\"EMA50\"] +df[\"EMA100\"]-df[\"EMA200\"]\n",
    "                \n",
    "                Indikatoren.MACD(df, 12, 26,9,\"_day\")\n",
    "                Indikatoren.MACD(df, 60, 130,45,\"_week\")    \n",
    "                \n",
    "\n",
    "                returns_multiple = 100*round(stock_return-1.0, 4)\n",
    "                print (f'Ticker: {ticker}; Returns Multiple: {returns_multiple:.2f} %\\n')\n",
    "                df.to_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', float_format='%.5f',)               \n",
    "            ## schreibe Ticker und die Longnames raus !\n",
    "            _ticker_names = pd.DataFrame(list(zip(true_tickers,true_names,true_industry,true_sector,true_marketCap)),\n",
    "                            columns=['ticker','name','industry',\"sector\",\"marketCap\"])\n",
    "            _ticker_names = _ticker_names.sort_values(\"ticker\")               \n",
    "            _ticker_names.to_csv(tmpdatafile +\"//\"+ \"_ticker_names.csv\",sep=\";\")  \n",
    "        \n",
    "        if shitflag==False:\n",
    "            shitflag = True    \n",
    "            shit_file = open(resfile+\"//\"+\"_shit\"+'.csv','w')\n",
    "            for item in shit_list:\n",
    "                shit_file.write(item+\"\\n\")\n",
    "            shit_file.close()    \n",
    "\n",
    "print(\"Done so far. This is what has been written to the csv..: \\n\\n\")\n",
    "df = pd.read_csv(tmpdatafile + \"//\"+'holc_data.csv',sep=\";\",decimal=',', \n",
    "                            parse_dates=True,\n",
    "                            index_col=0)\n",
    "print(df.head(5))\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(df.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
